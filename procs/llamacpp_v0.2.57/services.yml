services:
  # instruction
  - serviceId: llama.cpp|SakanaAI-EvoLLM-JP-v1-7B_q5_K_M|TI|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextInstruction
    description: an experimental general-purpose Japanese LLM.
    license: Microsoft Research License
    url: https://huggingface.co/SakanaAI/EvoLLM-JP-v1-7B
    properties:
      commands:
        - bash
        - run_repl.sh
        - SakanaAI/EvoLLM-JP-v1-7B
        - mmnga/SakanaAI-EvoLLM-JP-v1-7B-gguf
        - "*q5_K_M.gguf"
      requiredGpuMemoryMBs: [5314]

  - serviceId: llama.cpp|SakanaAI-EvoLLM-JP-v1-7B_q5_K_S|TI|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextInstruction
    description: an experimental general-purpose Japanese LLM.
    license: Microsoft Research License
    url: https://huggingface.co/SakanaAI/EvoLLM-JP-v1-7B
    properties:
      commands:
        - bash
        - run_repl.sh
        - SakanaAI/EvoLLM-JP-v1-7B
        - mmnga/SakanaAI-EvoLLM-JP-v1-7B-gguf
        - "*q5_K_S.gguf"
      requiredGpuMemoryMBs: [5314]

  - serviceId: llama.cpp|SakanaAI-EvoLLM-JP-v1-7B_q8_0|TI|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextInstruction
    description: an experimental general-purpose Japanese LLM.
    license: Microsoft Research License
    url: https://huggingface.co/SakanaAI/EvoLLM-JP-v1-7B
    properties:
      commands:
        - bash
        - run_repl.sh
        - SakanaAI/EvoLLM-JP-v1-7B
        - mmnga/SakanaAI-EvoLLM-JP-v1-7B-gguf
        - "*q8_0.gguf"
      requiredGpuMemoryMBs: [7719]


  - serviceId: llama.cpp|SakanaAI-EvoLLM-JP-A-v1-7B_q5_K_M|TI|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextInstruction
    description: an experimental general-purpose Japanese LLM.
    license: Apache License, Version 2.0
    url: https://huggingface.co/SakanaAI/EvoLLM-JP-A-v1-7B
    properties:
      commands:
        - bash
        - run_repl.sh
        - SakanaAI/EvoLLM-JP-A-v1-7B
        - mmnga/SakanaAI-EvoLLM-JP-A-v1-7B-gguf
        - "*q5_K_M.gguf"
      requiredGpuMemoryMBs: [5314]

  - serviceId: llama.cpp|SakanaAI-EvoLLM-JP-A-v1-7B_q5_K_S|TI|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextInstruction
    description: an experimental general-purpose Japanese LLM.
    license: Apache License, Version 2.0
    url: https://huggingface.co/SakanaAI/EvoLLM-JP-A-v1-7B
    properties:
      commands:
        - bash
        - run_repl.sh
        - SakanaAI/EvoLLM-JP-A-v1-7B
        - mmnga/SakanaAI-EvoLLM-JP-A-v1-7B-gguf
        - "*q5_K_S.gguf"
      requiredGpuMemoryMBs: [5314]

  - serviceId: llama.cpp|SakanaAI-EvoLLM-JP-A-v1-7B_q8_0|TI|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextInstruction
    description: an experimental general-purpose Japanese LLM.
    license: Apache License, Version 2.0
    url: https://huggingface.co/SakanaAI/EvoLLM-JP-A-v1-7B
    properties:
      commands:
        - bash
        - run_repl.sh
        - SakanaAI/EvoLLM-JP-A-v1-7B
        - mmnga/SakanaAI-EvoLLM-JP-A-v1-7B-gguf
        - "*q8_0.gguf"
      requiredGpuMemoryMBs: [7719]

  # chat
  - serviceId: llama.cpp|SakanaAI-EvoLLM-JP-v1-7B_q5_K_M|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    description: an experimental general-purpose Japanese LLM.
    license: Microsoft Research License
    url: https://huggingface.co/SakanaAI/EvoLLM-JP-v1-7B
    properties:
      commands:
        - bash
        - run_repl.sh
        - SakanaAI/EvoLLM-JP-v1-7B
        - mmnga/SakanaAI-EvoLLM-JP-v1-7B-gguf
        - "*q5_K_M.gguf"
      requiredGpuMemoryMBs: [5314]

  - serviceId: llama.cpp|SakanaAI-EvoLLM-JP-v1-7B_q5_K_S|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    description: an experimental general-purpose Japanese LLM.
    license: Microsoft Research License
    url: https://huggingface.co/SakanaAI/EvoLLM-JP-v1-7B
    properties:
      commands:
        - bash
        - run_repl.sh
        - SakanaAI/EvoLLM-JP-v1-7B
        - mmnga/SakanaAI-EvoLLM-JP-v1-7B-gguf
        - "*q5_K_S.gguf"
      requiredGpuMemoryMBs: [5314]

  - serviceId: llama.cpp|SakanaAI-EvoLLM-JP-v1-7B_q8_0|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    description: an experimental general-purpose Japanese LLM.
    license: Microsoft Research License
    url: https://huggingface.co/SakanaAI/EvoLLM-JP-v1-7B
    properties:
      commands:
        - bash
        - run_repl.sh
        - SakanaAI/EvoLLM-JP-v1-7B
        - mmnga/SakanaAI-EvoLLM-JP-v1-7B-gguf
        - "*q8_0.gguf"
      requiredGpuMemoryMBs: [7719]

  - serviceId: llama.cpp|SakanaAI-EvoLLM-JP-A-v1-7B_q5_K_M|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    description: an experimental general-purpose Japanese LLM.
    license: Apache License, Version 2.0
    url: https://huggingface.co/SakanaAI/EvoLLM-JP-A-v1-7B
    properties:
      commands:
        - bash
        - run_repl.sh
        - SakanaAI/EvoLLM-JP-A-v1-7B
        - mmnga/SakanaAI-EvoLLM-JP-A-v1-7B-gguf
        - "*q5_K_M.gguf"
      requiredGpuMemoryMBs: [5314]

  - serviceId: llama.cpp|SakanaAI-EvoLLM-JP-A-v1-7B_q5_K_S|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    description: an experimental general-purpose Japanese LLM.
    license: Apache License, Version 2.0
    url: https://huggingface.co/SakanaAI/EvoLLM-JP-A-v1-7B
    properties:
      commands:
        - bash
        - run_repl.sh
        - SakanaAI/EvoLLM-JP-A-v1-7B
        - mmnga/SakanaAI-EvoLLM-JP-A-v1-7B-gguf
        - "*q5_K_S.gguf"
      requiredGpuMemoryMBs: [5314]

  - serviceId: llama.cpp|SakanaAI-EvoLLM-JP-A-v1-7B_q8_0|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    description: an experimental general-purpose Japanese LLM.
    license: Apache License, Version 2.0
    url: https://huggingface.co/SakanaAI/EvoLLM-JP-A-v1-7B
    properties:
      commands:
        - bash
        - run_repl.sh
        - SakanaAI/EvoLLM-JP-A-v1-7B
        - mmnga/SakanaAI-EvoLLM-JP-A-v1-7B-gguf
        - "*q8_0.gguf"
      requiredGpuMemoryMBs: [7719]


  - serviceId: llama.cpp|Swallow-MX-8x7b-NVE-v0.1_q8_0|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    description: Our Swallow-MX-8x7b-NVE-v0.1 model has undergone continuous pre-training from the Mixtral-8x7B-Instruct-v0.1, primarily with the addition of Japanese language data.
    license: Apache License, Version 2.0
    url: https://huggingface.co/tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1
    properties:
      commands:
        - bash
        - run_repl.sh
        - tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1
        - mmnga/tokyotech-llm-Swallow-MX-8x7b-NVE-v0.1-gguf
        - "*q8_0.gguf"
      requiredGpuMemoryMBs: [47913]

  - serviceId: llama.cpp|Swallow-MX-8x7b-NVE-v0.1_q5_K_M|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    description: Our Swallow-MX-8x7b-NVE-v0.1 model has undergone continuous pre-training from the Mixtral-8x7B-Instruct-v0.1, primarily with the addition of Japanese language data.
    license: Apache License, Version 2.0
    url: https://huggingface.co/tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1
    properties:
      commands:
        - bash
        - run_repl.sh
        - tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1
        - mmnga/tokyotech-llm-Swallow-MX-8x7b-NVE-v0.1-gguf
        - "*q5_K_M.gguf"
      requiredGpuMemoryMBs: [32323]

  - serviceId: llama.cpp|Swallow-MX-8x7b-NVE-v0.1_q5_K_S|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    description: Our Swallow-MX-8x7b-NVE-v0.1 model has undergone continuous pre-training from the Mixtral-8x7B-Instruct-v0.1, primarily with the addition of Japanese language data.
    license: Apache License, Version 2.0
    url: https://huggingface.co/tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1
    properties:
      commands:
        - bash
        - run_repl.sh
        - tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1
        - mmnga/tokyotech-llm-Swallow-MX-8x7b-NVE-v0.1-gguf
        - "*q5_K_S.gguf"
      requiredGpuMemoryMBs: [31371]

  - serviceId: llama.cpp|Japanese-Starling-ChatV-7B-GGUF_Q4_K_M|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    description: a Japanese chat model built on top of "chatntq-ja-7b-v1.0", originally based on Mistral-7B-v0.1.
    license: Apache License, Version 2.0
    url: https://huggingface.co/TFMC/Japanese-Starling-ChatV-7B-GGUF
    properties:
      commands:
        - bash
        - run_repl.sh
        - NTQAI/chatntq-ja-7b-v1.0
        - TFMC/Japanese-Starling-ChatV-7B-GGUF
        - "*Q4_K_M.gguf"
      requiredGpuMemoryMBs: [7751]

  - serviceId: llama.cpp|Japanese-Starling-ChatV-7B-GGUF_Q8_0|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    description: a Japanese chat model built on top of "chatntq-ja-7b-v1.0", originally based on Mistral-7B-v0.1.
    license: Apache License, Version 2.0
    url: https://huggingface.co/TFMC/Japanese-Starling-ChatV-7B-GGUF
    properties:
      commands:
        - bash
        - run_repl.sh
        - NTQAI/chatntq-ja-7b-v1.0
        - TFMC/Japanese-Starling-ChatV-7B-GGUF
        - "*Q8_0.gguf"
      requiredGpuMemoryMBs: [7751]

  - serviceId: llama.cpp|Japanese-Starling-ChatV-7B-GGUF_f16|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    description: a Japanese chat model built on top of "chatntq-ja-7b-v1.0", originally based on Mistral-7B-v0.1.
    license: Apache License, Version 2.0
    url: https://huggingface.co/TFMC/Japanese-Starling-ChatV-7B-GGUF
    properties:
      commands:
        - bash
        - run_repl.sh
        - NTQAI/chatntq-ja-7b-v1.0
        - TFMC/Japanese-Starling-ChatV-7B-GGUF
        - "*f16.gguf"
      requiredGpuMemoryMBs: [13997]
