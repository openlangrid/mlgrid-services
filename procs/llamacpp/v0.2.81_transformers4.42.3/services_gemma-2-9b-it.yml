common:
  description: Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.
  license: gemma
  url: https://huggingface.co/google/gemma-2-9b-it

services:
  # 9b-it
  - serviceId: transformers|gemma-2-9b-it|TG|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextGeneration
    properties:
      commands:
        - bash
        - run_transformers_repl.sh
        - google/gemma-2-9b-it
      requiredGpuMemoryMBs: [18461]

  - serviceId: transformers|gemma-2-9b-it|TI|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextInstruction
    properties:
      commands:
        - bash
        - run_transformers_repl.sh
        - google/gemma-2-9b-it
      requiredGpuMemoryMBs: [18461]

  - serviceId: transformers|gemma-2-9b-it|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    properties:
      commands:
        - bash
        - run_transformers_repl.sh
        - google/gemma-2-9b-it
      requiredGpuMemoryMBs: [18461]

  # 9b-it, Q8_0
  - serviceId: llama.cpp|gemma-2-9b-it_QuantFactory_Q8_0|TG|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextGeneration
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-9b-it
        - QuantFactory/Gemma-2-9B-It-SPPO-Iter3-GGUF
        - "*Q8_0.gguf"
      requiredGpuMemoryMBs: [3665]

  - serviceId: llama.cpp|gemma-2-9b-it_QuantFactory_Q8_0|TI|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextInstruction
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-9b-it
        - QuantFactory/Gemma-2-9B-It-SPPO-Iter3-GGUF
        - "*Q8_0.gguf"
      requiredGpuMemoryMBs: [3665]

  - serviceId: llama.cpp|gemma-2-9b-it_QuantFactory_Q8_0|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-9b-it
        - QuantFactory/Gemma-2-9B-It-SPPO-Iter3-GGUF
        - "*Q8_0.gguf"
      requiredGpuMemoryMBs: [3665]
