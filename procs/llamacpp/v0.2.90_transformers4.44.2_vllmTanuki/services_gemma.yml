common:
  description: Gemma is a series of best-in-class open models and draws inspiration and technological lineage from the Gemini family of models.
  license: gemma
  url: https://huggingface.co/google/gemma-2-2b-jpn-it

services:
  # transformers
  - serviceId: transformers|gemma-2-2b-jpn-it|TG|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextGeneration
    properties:
      commands:
        - bash
        - run_transformers_repl.sh
        - google/gemma-2-2b-jpn-it
      requiredGpuMemoryMBs: [5691]

  - serviceId: transformers|gemma-2-2b-jpn-it|TI|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextInstruction
    properties:
      commands:
        - bash
        - run_transformers_repl.sh
        - google/gemma-2-2b-jpn-it
      requiredGpuMemoryMBs: [5691]

  - serviceId: transformers|gemma-2-2b-jpn-it|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    properties:
      commands:
        - bash
        - run_transformers_repl.sh
        - google/gemma-2-2b-jpn-it
      requiredGpuMemoryMBs: [5691]

  # gguf Q8
  - serviceId: llama.cpp|gemma-2-2b-jpn-it_NikolayKozloff_Q8_0|TG|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextGeneration
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-2b-jpn-it
        - NikolayKozloff/gemma-2-2b-jpn-it-Q8_0-GGUF
        - "*.gguf"
      requiredGpuMemoryMBs: [3533]

  - serviceId: llama.cpp|gemma-2-2b-jpn-it_NikolayKozloff_Q8_0|TI|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextInstruction
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-2b-jpn-it
        - NikolayKozloff/gemma-2-2b-jpn-it-Q8_0-GGUF
        - "*.gguf"
      requiredGpuMemoryMBs: [3533]

  - serviceId: llama.cpp|gemma-2-2b-jpn-it_NikolayKozloff_Q8_0|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-2b-jpn-it
        - NikolayKozloff/gemma-2-2b-jpn-it-Q8_0-GGUF
        - "*.gguf"
      requiredGpuMemoryMBs: [3533]


  # gguf Q8
  - serviceId: llama.cpp|gemma-2-2b-jpn-it_alfredplpl_Q8_0|TG|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextGeneration
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-2b-jpn-it
        - alfredplpl/gemma-2-2b-jpn-it-gguf
        - "*Q8_0.gguf"
      requiredGpuMemoryMBs: [3533]

  - serviceId: llama.cpp|gemma-2-2b-jpn-it_alfredplpl_Q8_0|TI|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextInstruction
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-2b-jpn-it
        - alfredplpl/gemma-2-2b-jpn-it-gguf
        - "*Q8_0.gguf"
      requiredGpuMemoryMBs: [3533]

  - serviceId: llama.cpp|gemma-2-2b-jpn-it_alfredplpl_Q8_0|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-2b-jpn-it
        - alfredplpl/gemma-2-2b-jpn-it-gguf
        - "*Q8_0.gguf"
      requiredGpuMemoryMBs: [3533]


  # gguf Q4_K_M
  - serviceId: llama.cpp|gemma-2-2b-jpn-it_alfredplpl_Q4_K_M|TG|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextGeneration
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-2b-jpn-it
        - alfredplpl/gemma-2-2b-jpn-it-gguf
        - "*Q4_K_M.gguf"
      requiredGpuMemoryMBs: [2507]

  - serviceId: llama.cpp|gemma-2-2b-jpn-it_alfredplpl_Q4_K_M|TI|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextInstruction
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-2b-jpn-it
        - alfredplpl/gemma-2-2b-jpn-it-gguf
        - "*Q4_K_M.gguf"
      requiredGpuMemoryMBs: [2507]

  - serviceId: llama.cpp|gemma-2-2b-jpn-it_alfredplpl_Q4_K_M|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-2b-jpn-it
        - alfredplpl/gemma-2-2b-jpn-it-gguf
        - "*Q4_K_M.gguf"
      requiredGpuMemoryMBs: [2507]


  # gguf IQ4_XS
  - serviceId: llama.cpp|gemma-2-2b-jpn-it_alfredplpl_IQ4_XS|TG|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextGeneration
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-2b-jpn-it
        - alfredplpl/gemma-2-2b-jpn-it-gguf
        - "*IQ4_XS.gguf"
      requiredGpuMemoryMBs: [2371]

  - serviceId: llama.cpp|gemma-2-2b-jpn-it_alfredplpl_IQ4_XS|TI|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplTextInstruction
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-2b-jpn-it
        - alfredplpl/gemma-2-2b-jpn-it-gguf
        - "*IQ4_XS.gguf"
      requiredGpuMemoryMBs: [2371]

  - serviceId: llama.cpp|gemma-2-2b-jpn-it_alfredplpl_IQ4_XS|Chat|R
    implementation: org.langrid.mlgridservices.service.impl.CmdReplChat
    properties:
      commands:
        - bash
        - run_llamacpppython_repl.sh
        - google/gemma-2-2b-jpn-it
        - alfredplpl/gemma-2-2b-jpn-it-gguf
        - "*IQ4_XS.gguf"
      requiredGpuMemoryMBs: [2371]